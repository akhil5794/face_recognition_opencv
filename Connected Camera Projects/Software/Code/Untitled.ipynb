{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\akhil\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "#from collections import namedtuple\n",
    "#import functools\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "#import PIL.Image\n",
    "import os\n",
    "import math\n",
    "\n",
    "from gtts import gTTS\n",
    "#import pyttsx3;\n",
    "#from io import BytesIO\n",
    "\n",
    "#from playsound import playsound\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from operator import itemgetter \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3]:\n",
    "\n",
    "\n",
    "def load_pb(path_to_pb):\n",
    "    with tf.io.gfile.GFile(path_to_pb, \"rb\") as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "load_pb('MobileFaceNet_9925_9680.pb')\n",
    "    \n",
    "inputs_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name(\"embeddings:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[5]:\n",
    "\n",
    "\n",
    "def image_to_embedding(image, embeddings):\n",
    "   \n",
    "    #image = cv2.resize(image, (112, 112), interpolation=cv2.INTER_CUBIC) \n",
    "    image = cv2.resize(image, (112, 112), interpolation=cv2.INTER_AREA) \n",
    "    \n",
    "    ### Image Thresholing added by Sourjeet\n",
    "    #_,image = cv2.threshold(image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    ###\n",
    "    \n",
    "    #image = cv2.resize(image, (112, 112)) \n",
    "    img = image[...,::-1]\n",
    "    x_train = np.array([img])\n",
    "    x_train = (x_train-127.5)*0.0078125 ## normalizing image from -1 to 1\n",
    "    with tf.Session() as sess:\n",
    "        embed = sess.run(embeddings, feed_dict={inputs_placeholder:x_train})\n",
    "\n",
    "    return sklearn.preprocessing.normalize(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[18]:\n",
    "\n",
    "\n",
    "def recognize_face(face_image, input_embeddings, embeddings, face_time):\n",
    "\n",
    "    embedding = image_to_embedding(face_image, embeddings)\n",
    "    #pd.DataFrame(embedding).to_csv(\"TestImageEmbedding.csv\")\n",
    "    \n",
    "    ## USe This \n",
    "    ## sorted(student_tuples, key=itemgetter(2), reverse=True)\n",
    "    index = 0\n",
    "    # Loop over  names and encodings.\n",
    "    for _, img_embedding, _ in input_embeddings:\n",
    "        \n",
    "        \n",
    "        \n",
    "        #input_embeddings[index][2] = np.sqrt(((embedding-img_embedding)**2).sum())\n",
    "        #input_embeddings[index][3] = distance.cosine(embedding,img_embedding)\n",
    "        input_embeddings[index][2] = distance.cosine(embedding,img_embedding)\n",
    "        index = index + 1\n",
    "\n",
    "    sorted_distance = sorted(input_embeddings, key=itemgetter(2), reverse=False)\n",
    "    #pd.DataFrame(input_embeddings).to_csv(\"image_details.csv\")\n",
    "    \n",
    "    return_str = \"Unknown_person\"\n",
    "    \n",
    "    #for i in list(range(5)):\n",
    "    #    print('Cosine distance from %s is %s' %(sorted_distance[i][0], sorted_distance[i][2]))\n",
    "    #    print('-----------------------------------------------')\n",
    "    \n",
    "    print('Cosine distance from %s is %s' %(sorted_distance[0][0], sorted_distance[0][2]))\n",
    "        \n",
    "    #print('###############################################')\n",
    "    print('-----------------------------------------------')\n",
    "    \n",
    "    if sorted_distance[0][2] < 0.6:\n",
    "        return_str = str(sorted_distance[0][0])   ##+\"|\"+str(sorted_distance[0][3])\n",
    "        current_time = datetime.now()\n",
    "        time_str_detected = face_time[return_str]\n",
    "        diff_time = (current_time - time_str_detected).seconds\n",
    "#         if diff_time > 10: \n",
    "#             face_time[return_str] =  current_time\n",
    "#             print(\"Speaker Out: \" , return_str)\n",
    "#             tts = gTTS('hello '+return_str, 'en-in')\n",
    "#             tts.save('hello.mp3')\n",
    "#             os.system('mpg321 hello.mp3 &')     \n",
    "#             return return_str\n",
    "    else:\n",
    "        return \"Unknown_person\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[7]:\n",
    "\n",
    "\n",
    "import glob\n",
    "import sklearn.preprocessing\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "def get_class(img_path):\n",
    "    return str(img_path.split('/')[-2])\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def create_input_image_embeddings():\n",
    "    ##input_embeddings = {}\n",
    "    \n",
    "    ##change by Sourjeet\n",
    "    input_embeddings_all = []\n",
    "    initial_timestamp = datetime.now()\n",
    "    face_time = {}\n",
    "    \n",
    "    for file in glob.glob(\"./../Images/*/*\"):\n",
    "        #print (file)\n",
    "        \n",
    "        person_name = get_class(file)\n",
    "        \n",
    "        \n",
    "        image_file = cv2.imread(file, 1)\n",
    "        \n",
    "        ##change by Sourjeet\n",
    "        input_embeddings_all.append([person_name,image_to_embedding(image_file, embeddings),1])\n",
    "        \n",
    "        face_time[person_name] = initial_timestamp\n",
    "        \n",
    "        create_input_image_embeddings_out = [input_embeddings_all,face_time]\n",
    "        \n",
    "         \n",
    "    return create_input_image_embeddings_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[16]:\n",
    "\n",
    "\n",
    "def recognize_faces_in_cam(input_embeddings,face_time):\n",
    "    \n",
    "\n",
    "    cv2.namedWindow(\"Face Recognizer\")\n",
    "    vc = cv2.VideoCapture(0)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    #face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "    \n",
    "    \n",
    "    while vc.isOpened():\n",
    "        #ret, frame = vc.read()\n",
    "        #print(ret)\n",
    "        #img = frame\n",
    "        \n",
    "        frame = vc.read()[1]\n",
    "        frameID = vc.get(1)\n",
    "        #print(frameID)\n",
    "        if(frameID % math.floor(5) == 0):\n",
    "            #print(frameID)\n",
    "            height, width, channels = frame.shape\n",
    "            \n",
    "    \n",
    "        \t#if ret:\n",
    "            #\tcv2.imwrite('frame{:d}.jpg'.format(count), frame)\n",
    "            #\tcount += 30 # i.e. at 30 fps, this advances one second\n",
    "            #\tcap.set(1, count)\n",
    "        \t#else:\n",
    "            #\tcap.release()\n",
    "            #break\n",
    "            \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "            # Loop through all the faces detected \n",
    "            #identities = []\n",
    "            for (x, y, w, h) in faces:\n",
    "                x1 = x\n",
    "                y1 = y\n",
    "                x2 = x+w\n",
    "                y2 = y+h\n",
    "    \n",
    "                face_image = frame[max(0, y1):min(height, y2), max(0, x1):min(width, x2)]    \n",
    "                identity= recognize_face(face_image, input_embeddings, embeddings,face_time)\n",
    "            \n",
    "                if identity is not None:\n",
    "                    img = cv2.rectangle(frame,(x1, y1),(x2, y2),(255,255,255),2)\n",
    "                    cv2.putText(img, str(identity), (x1+5,y1-5), font, 1, (255,255,255), 2)\n",
    "            \n",
    "                    key = cv2.waitKey(15)\n",
    "                    cv2.imshow(\"Face Recognizer\", img)\n",
    "                    if key == 27: # exit on ESC\n",
    "                        break    \n",
    "    vc.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[16]:\n",
    "\n",
    "\n",
    "def recognize_faces_in_cam(input_embeddings,face_time):\n",
    "    \n",
    "\n",
    "    cv2.namedWindow(\"Face Recognizer\")\n",
    "    vc = cv2.VideoCapture(0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    #face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "    \n",
    "    \n",
    "    while vc.isOpened():\n",
    "        #ret, frame = vc.read()\n",
    "        #print(ret)\n",
    "        #img = frame\n",
    "        \n",
    "        frame = vc.read()[1]\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        # Loop through all the faces detected \n",
    "        #identities = []\n",
    "        for (x, y, w, h) in faces:\n",
    "            x1 = x\n",
    "            y1 = y\n",
    "            x2 = x+w\n",
    "            y2 = y+h\n",
    "\n",
    "            face_image = frame[max(0, y1):min(height, y2), max(0, x1):min(width, x2)]    \n",
    "            identity= recognize_face(face_image, input_embeddings, embeddings,face_time)\n",
    "\n",
    "            if identity is not None:\n",
    "                img = cv2.rectangle(frame,(x1, y1),(x2, y2),(255,255,255),2)\n",
    "                cv2.putText(img, str(identity), (x1+5,y1-5), font, 1, (255,255,255), 2)\n",
    "\n",
    "                key = cv2.waitKey(15)\n",
    "                cv2.imshow(\"Face Recognizer\", img)\n",
    "                if key == 27: # exit on ESC\n",
    "                    break    \n",
    "    vc.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[11]:\n",
    "\n",
    "\n",
    "create_input_image_embeddings_out = create_input_image_embeddings()\n",
    "input_embeddings = create_input_image_embeddings_out[0] \n",
    "face_time = create_input_image_embeddings_out[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[19]:\n",
    "\n",
    "\n",
    "recognize_faces_in_cam(input_embeddings,face_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
